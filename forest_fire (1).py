# -*- coding: utf-8 -*-
"""FOREST FIRE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GmuKIHUP9IPeFTxq1_S24IKoVv94VA-t
"""

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns

dataset=pd.read_csv("/content/Algerian_forest_fires_dataset_UPDATE.csv",header=1)

dataset.info()

dataset.head()

dataset.isnull()

dataset.describe()

"""**DATA CLEANING**"""

dataset[dataset.isnull().any(axis=1)]
#CHECKING FOR THE NULL VALUES FROM STARTING POINT OR AAXIS 1 AND PRINTING THE COLUM HAVING NULL VALUE.
#dataset.isnull() return the NaN as value if it doesn't have any null value.
#dataset[dataset.isnull()] returns the boolean as the value for the isnull.

#since we have the data of two separate regions
#1. bejain
#2.sidi-bel
#now we shall add new column as region and assign the values for each regions.
dataset.loc[:122,"Region"]=0
dataset.loc[122:,"Region"]=1

df=dataset

df.info()

df.isnull().sum()
#checkin gfor the sum of null values in each column.

df[['Region']]=df[['Region']].astype(int)
# converting the string 0 of region assigned previouls into integer.

df.head()

df.isnull().sum()

#droping the null values

df=df.dropna().reset_index(drop=True)

df.head()

df.isnull().sum()

df.iloc[[122]]# getting the details of the row 122

#since we have the values of row 122 as string and values of sidi-bel header we shall remove them
df=df.drop(122).reset_index(drop=True)

df.iloc[[122]]

## fix spaces in columns names
df.columns=df.columns.str.strip()
df.columns

df.info()

"""CONVERTING THE DATATYPE OF THE COLUMNS

"""

# since we have all the columns name exxept region as object we need to convert them into intergers

df[['day','month','year','Temperature','RH','Ws']]=df[['day','month','year','Temperature','RH','Ws']].astype(int)

df.info()

df.head()

objects=[features for features in df.columns if df[features].dtypes=='O']

for i in objects:
    if i!='Classes':
        df[i]=df[i].astype(float)

df.info()

# another way of converting the data type to float.
#df[['Rain','FFMC','DMC',"DC",'ISI',"BUI","FWI"]]=df[['Rain','FFMC','DMC',"DC",'ISI',"BUI","FWI"]].astype(float)

df.describe()

objects

df.head()

df.to_csv("Algerian_forest_fires_cleaned_dataset.csv",index=False)

"""**#EXPLORATORY DATA ANALYSIS**"""

# dropping the unwanted or not so important colums from the dataset so to reduce the time and im]ncrease the accuracy

df_copy=df.drop(['day','month','year'],axis=1)
df

df_copy.head()

df_copy['Classes'].value_counts()

df_copy['Classes']=np.where(df_copy['Classes'].str.contains('not fire'),0,1)
# df[['Classes']]=df[['Classes']].map({'fire':0,"not fire":1})
# by using map function we can change the names of the class

df_copy.head()

df_copy.tail()

df_copy['Classes'].value_counts()

plt.style.use('seaborn')
df_copy.hist(bins=50,figsize=(20,15))
plt.show()

## Percentage for Pie Chart
percentage=df_copy['Classes'].value_counts(normalize=True)*100

percentage

#plotting PIECHART

fig = plt.figure(figsize =(10, 7))
title=['FIRE','NOT FIRE']
plt.pie(percentage, labels = title)
plt.title("PIE CHART OF CLAsses")
plt.legend()

# show plot
plt.show()

#correlation

df_copy.corr()

sns.heatmap(df.corr())



sns.heatmap(df_copy)

sns.boxplot(df['FWI'],color='red')

df.head()

df['Classes']=np.where(df['Classes'].str.contains('not fire'),'0','1')

## Monthly Fire Analysis
dftemp=df.loc[df['Region']==1]
plt.subplots(figsize=(13,6))
sns.set_style('whitegrid')
sns.countplot(x='month',hue='Classes',data=df)
plt.ylabel('Number of Fires',weight='bold')
plt.xlabel('Months',weight='bold')
plt.title("Fire Analysis of Sidi- Bel Regions",weight='bold')

## Monthly Fire Analysis
dftemp=df.loc[df['Region']==0]
plt.subplots(figsize=(13,6))
sns.set_style('whitegrid')
sns.countplot(x='month',hue='Classes',data=df)
plt.ylabel('Number of Fires',weight='bold')
plt.xlabel('Months',weight='bold')
plt.title("Fire Analysis of Brjaia Regions",weight='bold')

"""**TRAINING THE MODEL
**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
# %matplotlib inline

df=pd.read_csv("/content/Algerian_forest_fires_cleaned_dataset.csv")

df.head()

df.columns

df.drop(['day','month','year'],axis=1,inplace=True)

df.head()

## Encoding
df['Classes']=np.where(df['Classes'].str.contains("not fire"),0,1)

df.tail()

df['Classes'].value_counts()

## Independent And dependent features
X=df.drop('Classes',axis=1)
y=df['Classes']

X.head()

X

y

X.describe()

#Train Test Split
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)

X_train.shape,X_test.shape

X_train.corr()

plt.figure(figsize=(12,10))
corr=X_train.corr()
sns.heatmap(corr)

def correlation(dataset, threshold):
    col_corr = set()
    corr_matrix = dataset.corr()
    for i in range(len(corr_matrix.columns)):
        for j in range(i):
            if abs(corr_matrix.iloc[i, j]) > threshold:
                colname = corr_matrix.columns[i]
                col_corr.add(colname)
    return col_corr

#The function correlation takes in two parameters: dataset and threshold.

#dataset is the input dataset for which we want to find correlated columns.
#threshold is the threshold value that determines the minimum absolute correlation value required for two columns to be considered correlated.
#The function calculates the correlation matrix of the dataset using the corr() method.

#Next, it iterates through the upper triangle of the correlation matrix using nested loops. For each pair of columns, it checks if the absolute correlation value is greater than the threshold. If it is, it adds the name of the column (from the second column of the pair) to the col_corr set.

#Finally, the function returns the set of column names that are correlated above the given threshold.

corr_features=correlation(X_train,0.85)
#assigning the threshold to 0.85

corr_features

## drop features when correlation is more than 0.85
X_train.drop(corr_features,axis=1,inplace=True)
X_test.drop(corr_features,axis=1,inplace=True)
X_train.shape,X_test.shape

"""**FEATURE SCALING OR STANDARDIZATION**"""

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
X_train_scaled=scaler.fit_transform(X_train)
X_test_scaled=scaler.fit_transform(X_test)

X_test_scaled[4]

X_train

X_test

y_train

y_test

"""Box Plots To understand Effect Of Standard Scaler"""

plt.subplots(figsize=(15, 5))
plt.subplot(1, 2, 1)
sns.boxplot(data=X_train)
plt.title('X_train Before Scaling')
plt.subplot(1, 2, 2)
sns.boxplot(data=X_train_scaled)
plt.title('X_train After Scaling')

"""**MODEL SELECTiON **"""

# since the dataset has two classes i.e "not fire" or "fire"
#this is any classification problem

#various models for cassification problems are :
#Logistic regression
#SVM
#KNN

"""**1.Linear Regression**"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
from joblib import dump,load


#from sklearn.linear_model import LinearRegression
#from sklearn.tree import DecisionTreeRegressor
#from sklearn.ensemble import RandomForestRegressor

model=LinearRegression()
model.fit(X_train_scaled,y_train)
y_pred=model.predict(X_test_scaled)
mean=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("mean score:",mean)
print("R2score:",score)

"""****Lasso Regression****"""

from sklearn.linear_model import Lasso
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score

model2=Lasso()
model2.fit(X_train_scaled,y_train)
y_pred=model2.predict(X_test_scaled)
mean2=mean_absolute_error(y_test,y_pred)
score2=r2_score(y_test,y_pred)
print("mean:",mean2)
print("r2_score:",score2)

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
model3=Ridge()
model3.fit(X_train_scaled,y_train)
y_pred=model3.predict(X_test_scaled)
mean3=mean_absolute_error(y_test,y_pred)
score3=r2_score(y_test,y_pred)
print("mean:",mean3)
print("score3:",score3)

from sklearn.linear_model import LassoCV
lassocv=LassoCV(cv=5)
lassocv.fit(X_train_scaled,y_train)

lassocv.alpha_



y_pred=lassocv.predict(X_test_scaled)

mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("Mean absolute error", mae)
print("R2 Score", score)

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
ridge=Ridge()
ridge.fit(X_train_scaled,y_train)
y_pred=ridge.predict(X_test_scaled)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("Mean absolute error", mae)
print("R2 Score", score)

from sklearn.linear_model import RidgeCV
ridgecv=RidgeCV(cv=5)
ridgecv.fit(X_train_scaled,y_train)
y_pred=ridgecv.predict(X_test_scaled)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("Mean absolute error", mae)
print("R2 Score", score)

from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
elastic=ElasticNet()
elastic.fit(X_train_scaled,y_train)
y_pred=elastic.predict(X_test_scaled)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("Mean absolute error", mae)
print("R2 Score", score)

#to save the model
from joblib import dump,load
dump(model,"forest.joblib")

import numpy as np
model=load("/content/forest.joblib")

features=np.array([[-0.66887916,  0.25676118, -0.38305751, -0.39346542,  0.48465752,
        0.12810653, -0.00321729,  0.98373875]])
model.predict(features)

